Implementation of the passes described in the previous section was started as
an \needspolish{probably don't need to mention this}\emph{out-of-source} LLVM
project outside the LLVM repository. \texttt{opt} can include the generated
object files through the \texttt{-load=\textit{objectfile}} option and use the
passes they comprise.

\section{Analysis}

\texttt{-load=\textit{object-file}} option and use the passes they comprise.

\subsection{Preprocessing}

\paragraph{Call instructions}

As mentioned in \ref{basic-block-model}, normal function calls do not terminate
basic blocks in LLVM. To allow for easier traversal and uniform handling when
instrumenting, we split those blocks after a call instruction and associate the
remainder with the function that was called, for later lookup.

\tobewritten[inline]{can easily be reverted later, but would we actually need
that?}
\tobewritten[inline]{does not apply to declarations}
\tobewritten[inline]{explain gateway functions}
\tobewritten[inline]{function pointers?}
\tobewritten[inline]{expand}

\paragraph{CFG aliasing}

Branch fan-in nodes can exhibit aliasing as explained in
\ref{aliasing-explained}. We chose to deal with this by inserting basic blocks
acting as a proxy on the offending edges in the CFG.  These \needspolish{is
this a good term?}proxy blocks will not contain actual code apart from the
signature check and update.

\tobewritten[inline]{statistics on actual use of this}
\tobewritten[inline]{expand}

\paragraph{Externally visible functions}

Functions that are visible outside the translation unit being processed
generally cannot reason about their potential set of callers. With no specific
callers, a signature update cannot be defined in a meaningful way. Even if the
set of CFCSS-aware callers was known—e.g. determined by an external
process and passed to the instrumentation stage as a parameter—the possibility
remains for externally visible functions to be called from code that does not
know or care about CFCSS. As a result, they cannot rely on the GSR or
D containing sensible values in these cases.

One option would be to simply not question the validity of the initial control
flow transfer to the function and use signatures only for control flow within
the function and any subsequent calls to CFCSS-aware functions. Yet this is
overly pessimistic in the case of recursive functions, e.g. an instrumented
\emph{qsort}.

After the initial control flow transfer we would instead like recursive calls
to be subject to signature checks in order to increase CFCSS coverage for the
translation unit in question. The containing basic blocks of the respective
call instructions form a fixed set of CFCSS-aware predecessors for the
function's entry block, such that a signature update can be defined. The
problem remains to figure out, upon entering the function, whether it was
called externally or recursively.

\tobewritten[inline]{gateway functions}

\paragraph{Function pointers} TODO

\tobewritten[inline]{function pointer candidates}
\tobewritten[inline]{difficulties in establishing correspondence}

\section{Instrumentation}


\subsection{Control-flow inside functions}

\paragraph{CFCSS registers}

Two new local variables are introduced in every function to hold the GSR and D.
For this purpose InstrumentBasicBlocks inserts two \texttt{alloca} instructions
for 64-bit integers into the entry block of each function.  Signature checks
will refer to these via \texttt{load} and \texttt{store} instructions that can
later be promoted to \todo{insert link to earlier explanation of SSA in
LLVM}virtual register \todo{is this the correct term?}references.

\paragraph{Error handling block}

\needspolish{Dopplung und schwurbelig} InstrumentBasicBlocks creates a new
basic block within each function to serve as the branch target for failed
signature comparisons. Since this work is focussed on evaluating CFCSS as
a means of error \emph{detection}, the error handling block will merely signal
the detected fault by raising an exception.  This is currently implemented as
a call to inline assembly containing the "undefined" \texttt{ud2}
instruction—generating an invalid opcode exception—and thus specific to the x86
architecture, yet it could likely be swapped for either the \texttt{llvm.trap}
or \texttt{llvm.debugtrap} intrinsics, that generate similar
instructions\footnote{\texttt{ud2} and \texttt{int3} in the case of x86} in
a platform-independent manner.

To allow for actual error \emph{handling}, the error handling block could
instead contain a call to a (possibly user-defined) fault handler, for instance
resetting the application to an earlier checkpoint, however this is outside the
scope of this work.


\paragraph{Detect aliasing}
\tobewritten{fill}

\subsection{Control-flow between functions}


\tobewritten[inline]{fill}

\section{Problems in using LLVM}

LLVM's primary purpose is to provide an optimizing compiler. As such it assumes
hardware to always work correctly. Especially the contents of registers and
normal memory locations may never unexpectedly change—which is precisely what
CFCSS anticipates and is looking to mitigate.

As a result, signature updates computing the bitwise XOR of an immediate
operand and a register whose contents are presumably known at most points in
time become candidates for \emph{constant folding}. Similarly, CFCSS checking
code appears to LLVM as a large collection of branches that will never be
taken, suggesting the use of \emph{dead code elimination}.

There is currently no way to mark certain instructions as off-limits to
subsequent optimization passes, likely because LLVM is not intended to be used
in this fashion. On the other hand, proper instrumentation should only add
instructions that are in fact required for CFCSS, which would eliminate the
need for further optimization, given cleanly written passes.

\tobewritten[inline]{currently evaluating whether "just not running additional
passes" will give the desired result reliably}

\tobewritten[inline]{mention LLVM Intrinsics, here or elsewhere}
